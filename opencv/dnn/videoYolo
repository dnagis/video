#!/usr/bin/python

#Passer une vidéo en YoloV3: basé sur simpleYoloV3


import cv2 as cv
import numpy as np
import sys

WHITE = (255, 255, 255)

FRAME_SKIPPER = 30 #mécanisme pour ne traiter qu'une partie des frames


#Parsing des arguments
if len(sys.argv) < 3:
    print("Mauvais nombre d args Usage:  videoYolo CI_threshold file")
    sys.exit(1)
    
#print("n args=", len(sys.argv))

conf_threshold = float(sys.argv[1]) #premier argument = CI

VIDEO_FILE = sys.argv[len(sys.argv)-1]
print("fichier video = ", VIDEO_FILE)



#PATH de recherche prepended aux fichiers weight, config, class names...
PATH='/initrd/mnt/dev_save/packages/cv_dnn_data/detection/yolov3-opencv/'

#Fichier des résultats, format gnuplot
gnuplot_file = open('results_gnuplot.txt', 'w')
#Fichier des résultats, format numpy sera results_numpy.npy




#Préparation Yolo
classes = open(PATH+'object_detection_classes_yolov3.txt').read().strip().split('\n')
np.random.seed(42)
colors = np.random.randint(0, 255, size=(len(classes), 3), dtype='uint8')
net = cv.dnn.readNetFromDarknet(PATH+'yolov3.cfg', PATH+'yolov3.weights') 
net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)
ln = net.getLayerNames()
ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]


#Yolo detection sur une frame
def do_detection(frame):
	detected = 0
	blob = cv.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)
	net.setInput(blob)
	outputs = net.forward(ln)
	outputs = np.vstack(outputs)
	for output in outputs:
		scores = output[5:] #pour chaque array de len=85, on récupère à partir de l'index 5
		classID = np.argmax(scores) #des 80 classes (object_detection_classes_yolov3.txt) celle qui a la valeur max
		confidence = scores[classID] #La confidence est la valeur à l'index de la classID
		
		#classID == 0 --> class = "person". 
		if ((classID==0) and (confidence > conf_threshold)):
			detected = 1		
			#print("frame n°=", pos_frames, " person CI=", confidence)	
	
	#print("frame n°=", pos_frames, "  detected=", detected)
	#gnuplot_file.write(str(pos_frames) + ' ' + str(detected) + '\n')
	return detected
	



cap = cv.VideoCapture(VIDEO_FILE)

#une list est faite pour append, numpy marche mal comme ça
results_list = []

while cap.isOpened():
	ret, frame = cap.read()
	pos_frames=int(cap.get(cv.CAP_PROP_POS_FRAMES))
	# if frame is read correctly ret is True
	if not ret:
		print("Can't receive frame (stream end?). Exiting ...")
		break

	#check divisibility par ce qui est après le "%", permet de skipper des frames
	if (pos_frames%FRAME_SKIPPER == 0): 
		result = do_detection(frame)
		print("frame n°=", pos_frames, "  detected=", result)
		results_list.append(result)
		
	if cv.waitKey(33) == ord('q'):
		break

numpy_array_results = np.array(results_list) 


#Saving the array au format numpy sera ouvert avec read = np.fromfile('results_numpy.npy', dtype=int)
numpy_array_results.tofile('results_numpy.npy')

print("Array de résultats:", numpy_array_results, " sauvegardé dans results_numpy.npy") 
     
        
cap.release()
cv.destroyAllWindows()














