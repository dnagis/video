#!/usr/bin/python

#ObjectDetection neural network TensorFlow model: ssd_mobilenet_v2_coco_2018_03_29
#https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/


import cv2
import numpy as np

# load the COCO class names
with open('/initrd/mnt/dev_save/packages/opencv-4.6.0/samples/data/dnn/object_detection_classes_coco.txt', 'r') as f:
   class_names = f.read().split('\n')
 
# get a different color array for each of the classes
COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))

# load the DNN model
# http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz (180Mo, lien trouvé en dérivant une URL trouvée 
#	dans le tuto openCV "Conversion of TensorFlow Detection Models and Launch with OpenCV Python" en adaptant ssd_mobilenet_v1 à ce qui est dans la page learnopencv)
# 	Le tarball contient frozen_inference_graph.pb et pipeline.config
# Pour obtenir le .pbtxt: script dans les sources opencv: samples/dnn/tf_text_graph_ssd.py
# --> python tf_text_graph_ssd.py --input=frozen_inference_graph.pb --config=pipeline.config --output=ssd_mobilenet_v2_coco_2018_03_29.pbtxt
model = cv2.dnn.readNet(model='frozen_inference_graph.pb', config='ssd_mobilenet_v2_coco_2018_03_29.pbtxt',framework='TensorFlow')

# read the image from disk
image = cv2.imread('image.jpg') #vehicle-traffic-object-detection-test-image.jpg (asiat persons & bikes)
image_height, image_width, _ = image.shape
# create blob from image
blob = cv2.dnn.blobFromImage(image=image, size=(300, 300), mean=(104, 117, 123), swapRB=True)
# set the blob to the model
model.setInput(blob)
# forward pass through the model to carry out the detection
output = model.forward()





# loop over each of the detection
for detection in output[0, 0, :, :]:
   # extract the confidence of the detection
   confidence = detection[2]
   # draw bounding boxes only if the detection confidence is above...
   # ... a certain threshold, else skip
   if confidence > .4:
       # get the class id
       class_id = detection[1]
       # map the class id to the class
       class_name = class_names[int(class_id)-1]
       color = COLORS[int(class_id)]
       # get the bounding box coordinates
       box_x = detection[3] * image_width
       box_y = detection[4] * image_height
       # get the bounding box width and height
       box_width = detection[5] * image_width
       box_height = detection[6] * image_height
       # draw a rectangle around each detected object
       cv2.rectangle(image, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=2)
       # put the FPS text on top of the frame
       cv2.putText(image, class_name, (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
 
cv2.imshow('image', image)
#cv2.imwrite('image_result.jpg', image)
cv2.waitKey(0)
cv2.destroyAllWindows()



