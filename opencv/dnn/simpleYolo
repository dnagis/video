#!/usr/bin/python

#Detection Yolo, initielement basé sur helloYoloV3
#
#Usage: simpleYolo CI [t] img_file


import cv2 as cv
import numpy as np
import time
import sys

WHITE = (255, 255, 255)
img = None
outputs = None

#Parsing des arguments
if len(sys.argv) < 3:
    print("Mauvais nombre d args Usage:  simpleYolo CI [t] img_file")
    sys.exit(1)
    
#print("n args=", len(sys.argv))

conf_threshold = float(sys.argv[1]) #premier argument = CI

IMAGE_FILE = sys.argv[len(sys.argv)-1]
print("fichier image = ", IMAGE_FILE)

if sys.argv[2] == "t":
	print("Detection par tiny-yolo")
	#PPATH prepended aux fichiers weight, config, class names...
	PPATH='/initrd/mnt/dev_save/packages/cv_dnn_data/detection/yolov3-tiny/'
	CONFIG_FILE=PPATH+'yolov3-tiny.cfg'
	WEIGHT_FILE=PPATH+'yolov3-tiny.weights'
else:
	print("Detection par regular yolo")
	#PPATH prepended aux fichiers weight, config, class names...
	PPATH='/initrd/mnt/dev_save/packages/cv_dnn_data/detection/yolov3-opencv/'
	CONFIG_FILE=PPATH+'yolov3.cfg'
	WEIGHT_FILE=PPATH+'yolov3.weights'
	

# Load names of classes 
#J'ai pris le fichier de noms de classes:dans les sources openCV dans opencv-4.6.0/samples/data/dnn/
#Je le mets dans les deux PPATH (yolo et regular)
classes = open(PPATH+'object_detection_classes_yolov3.txt').read().strip().split('\n')

np.random.seed(42)

# Give the configuration and weight files for the model and load the network.
net = cv.dnn.readNetFromDarknet(CONFIG_FILE, WEIGHT_FILE) 

net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)
# net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)

# determine the output layer
ln = net.getLayerNames()
#print(len(ln), ln) #len=254
ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]




#Lecture du fichier image et création du blob 
img = cv.imread(IMAGE_FILE)

frameHeight = img.shape[0]
frameWidth = img.shape[1]
print('Image Rows (frameHeight): ',frameHeight)
print('Image Cols (frameWidth): ',frameWidth)

blob = cv.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)

net.setInput(blob)

#Forward(): where the magic occurs...
outputs = net.forward(ln)



#Debug de la sortie de forward()
#En yolov3:
# large objects (507, 85)
# medium objects (2028, 85)
# small objects (8112, 85)
#print("type de outputs: ", type(outputs)) 						# <class 'tuple'>
print("len de outputs: ", len(outputs))							# 3 en yolov3, 2 en tiny yolo
#print("type du premier element de outputs: ", type(outputs[1])) # <class 'numpy.ndarray'> (idem pour chacun des n)
for i in range(len(outputs)):
    #print("np.shape(outputs[i]):", np.shape(outputs[i]))
    print("np.shape(outputs[{0}]: {1}".format(i, np.shape(outputs[i])))




#Explication des arrays de taille 85
#Le fichier des classes object_detection_classes_yolov3.txt contient 80 classes d'objets
#The network outputs bounding boxes are each represented by a vector of a number of classes + 5 elements (80+5 = 85)
#The first 4 elements represent the center_x, center_y, width, and height. The fifth element represents the confidence that the bounding box encloses an object.
#The rest of the elements are the confidence associated with each class (i.e., object type). The box is assigned to the class corresponding to the highest score for the box.

#Voir un array de taille 85 (dont au moins un score contient une valeur de CI > 0)
#print("outputs[0][0] :", outputs[0][208])

# combine ("aplatir") the 3 outputs groups into 1 (10647, 85)
outputs = np.vstack(outputs) #(10647, 85)

#print("np.shape(outputs):", np.shape(outputs)) #(10647, 85)
#print(outputs[10000]) #voir un exemple

#i: pour debug: pour avoir accès aux résultats intéressants
i=0

for output in outputs:
	scores = output[5:] #pour chaque array de len=85, on récupère seulement à partir de l'index 5 (i.e. les CI pour chaque classe)
	
	#Afficher les 80 CI à chaque fois qu'on a au moins une valeur > 0
	#if (cv.countNonZero(scores) > 0):
	#	print("@index en cours=", i)
	#	print("au moins une valeur de CI > 0")
	#	print(scores)
	
	classID = np.argmax(scores) #des 80 classes (object_detection_classes_yolov3.txt) celle qui a la valeur max
	confidence = scores[classID] #La confidence est la valeur à l'index de la classID	
	#classID == 0 --> class = "person". 
	if ((classID==0) and (confidence > conf_threshold)):		
		print("person CI = ",confidence,"   raw box:", output[0], "\t", output[1],"\t",output[2],"\t",output[3])
		
		#Calcul bounding box: The first 4 elements represent the center_x, center_y, width, and height. The fifth element represents the confidence that the bounding box encloses an object.
		center_x = int(output[0] * frameWidth)
		center_y = int(output[1] * frameHeight)
		width = int(output[2] * frameWidth)
		height = int(output[3] * frameHeight)
		left = int(center_x - (width / 2))
		top = int(center_y - (height / 2))
		right = int(center_x + (width / 2))
		bottom = int(center_y + (height / 2))
		cv.rectangle(img, (left,top), (right,bottom), (0, 0, 255), 2) 
	
	i+=1	

#print("dernier index analysé=", i) #juste pour debug

#affichage image avec boxes de detection
#cv.imshow("Display window", img)
#k = cv.waitKey(0)






