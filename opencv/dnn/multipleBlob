#!/usr/bin/python

#dnn sur un blob multiple créé avec cv.dnn.blobFromImages
#https://pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/

import cv2 as cv
import numpy as np
import sys

FRAME_SKIPPER = 120 #mécanisme pour ne traiter qu'une partie des frames

images = [] #list of images we'll be passing through the network

#Lecture video, passage des frames dans la list "images"

cap = cv.VideoCapture(sys.argv[1])
while cap.isOpened():
	ret, frame = cap.read()
	pos_frames=int(cap.get(cv.CAP_PROP_POS_FRAMES))
	# if frame is read correctly ret is True
	if not ret:
		print("Can't receive frame (stream end?). Exiting le while videoCapture ...")
		break

	#check divisibility par ce qui est après le "%", permet de skipper des frames
	if (pos_frames%FRAME_SKIPPER == 0): 
		print("append de la frame n°", pos_frames)
		images.append(frame)
        
cap.release()
cv.destroyAllWindows()

print("Fin de la création de la liste de frames, taille de la liste: ", len(images))

#Analyse



#Yolo, préparation
PATH='/initrd/mnt/dev_save/packages/cv_dnn_data/detection/yolov3-opencv/'
classes = open(PATH+'object_detection_classes_yolov3.txt').read().strip().split('\n')
net = cv.dnn.readNetFromDarknet(PATH+'yolov3.cfg', PATH+'yolov3.weights') 
net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)
ln = net.getLayerNames()
ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]
blob = cv.dnn.blobFromImages(images, 1/255.0, (416, 416), swapRB=True, crop=False)
net.setInput(blob)

#Analyse
print("Analyse")
outputs = net.forward(ln)

#Comprendre l output
#print("type de l output total: ", type(outputs)) 			# <class 'tuple'>
#print("length de : l output total: ", len(outputs)) 		#len = 3 
#print("type d'un element de outputs: ", type(outputs[0])) 	#<class 'numpy.ndarray'> pour chaque element
#print("np.shape(outputs[0]):", np.shape(outputs[0]))		#(N, 507, 85) N = nb d'images passées à cv.dnn.blobFromImages
#print("np.shape(outputs[1]):", np.shape(outputs[1]))		#(N, 2028, 85)
#print("np.shape(outputs[2]):", np.shape(outputs[2]))		#(N, 8112, 85)

#la première frame:
#print("np.shape(outputs[0][0]):", np.shape(outputs[0][0]))	#(507, 85)
#print("np.shape(outputs[1][0]):", np.shape(outputs[1][0]))	#(2028, 85)
#print("np.shape(outputs[2][0]):", np.shape(outputs[2][0]))	#(8112, 85)

#tuple_frame = (outputs[0][0], outputs[1][0], outputs[2][0])
#print("type de tuple_frame: ", type(tuple_frame))

#combined_first_frame = np.vstack(tuple_first_frame) #combine ("aplatir") the 3 outputs groups into 1
#print("np.shape(combined_first_frame):", np.shape(combined_first_frame)) #(10647, 85)

#Pour iterate sur les frames il me faut le nombre d'elements dans la dimension la plus haute d'un des trois groupes (small, medium, large)
#print("len de la top dimension du premier groupe small: ", len(outputs[0])) #j'ai bien le nombre de frames

#iterate sur chaque frame
for i in range (0,len(outputs[0])):
	detected = 0
	tuple_frame = (outputs[0][i], outputs[1][i], outputs[2][i])
	combined_frame = np.vstack(tuple_frame) #combine ("aplatir") the 3 outputs groups into 1
	#print("np.shape(combined_frame):", np.shape(combined_frame)) #(10647, 85)
	for output in combined_frame:
		scores = output[5:] #pour chaque array de len=85, on récupère à partir de l'index 5
		classID = np.argmax(scores)
		confidence = scores[classID]
		
		#classID == 0 --> class = "person". 
		if ((classID==0) and (confidence>0.9)):
			detected = 1		
			#print("frame n°=", pos_frames, " person CI=", confidence)
	
	print("frame n°=", i, "  detected=", detected)
